---
title: "'Big data' og politologisk datavidenskab"
author:
  - Frederik Hjorth
  - Matt W. Loftis
subtitle: "Udkast, april 2020"
date:
  # "`r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    keep_tex: yes
    latex_engine: pdflatex
    number_sections: true
  word_document:
    number_sections: true
biblio-style: apsr
fontfamily: cochineal
fontsize: 12pt
geometry: margin=1in
bibliography: references.bib
spacing: double
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

'Big data' er overalt. Det gælder i dobbelt forstand: takket være drastiske stigninger i computeres hukommelse og regnekraft indeholder næsten alle computere i dag store, ustrukturerede datamængder. Mange af disse data er biprodukter af menneskelig adfærd, som i dag registreres og kvantificeres i historisk uset omfang. Men big data er også overalt i den forstand at begrebet 'big data' og beslægtede begreber er blevet almindeligt kendte og bredt anvendte, og ikke mindst genstand for stor kommerciel interesse. En hyppigt citeret artikel fra *Harvard Business Review* kaldte således "data scientist" for "det 21. århundredes mest sexede job" [@davenport2012data].

Alene den begrebslige udbredelse af big data gør det relevant at vide hvad det nærmere dækker over. Men big data er også reelt et væsentligt nybrud i forhold til de data og metoder, politologi og samfundsvidenskab traditionelt har betjent sig af. Big data muliggør analyser af politologiske emner som ville have været umulige med traditionelle metoder, men kræver også nye teknikker og metodiske værktøjer.

Formålet med dette kapitel er at introducere til de datatyper og metoder, begrebet big data dækker over. Først opridser vi begrebets betydning og historie. Dernæst diskuterer vi hvordan en række karakteristika ved big data skaber særlige udfordringer i forhold til at udvikle stærke forskningsdesigns. Herefter præsenterer vi en række specifikke tekniske værktøjer til behandling af big data. Afslutningsvis opridser vi nogle væsentlige etiske problematikker i relation til brugen af big data.

cites: @mullainathan2017machine, @varian2014big

# Hvad er big data?

I en toneangivende artikel peger @lazeretal på big data som kilden til en ny type samfundsvidenskab, "computational social science", med "kapacitet til at indsamle og analysere data med historisk uset bredde, dybde og omfang". Men begrebet big data lever to liv. På den ene side er den populære definition af begrebet forbundet med futuristiske løfter om ny, datadrevet videnskab og teknologi. På den anden side står hvad man kunne kalde den operationelle definition af hvordan store datamænger indsamles, lagres og analyseres af samfundsvidenskabsfolk. For at belyse betydningen af big data for politologi betragter vi først denne anden, operationelle betydning af begrebet inden vi vender tilbage til den første, populære betydning.

En bredt anvendt operationel definition identificerer big data med de såkaldte 'tre V'er': *Volume*, *Variety* og *Velocity*, dvs. volumen, variation og hastighed [@laney01]. Big data refererer her til foranderlige og meget store datasæt -- inklusive data der er for store til at gemme på en almindelig pc -- der indeholder masser af variation. Datakilder af denne art er ofte interessante for samfundsvidenskab: søgemaskinelogfiler, sociale medieaktiviteter, offentlige registre, mobiltelefonregistre eller endda data gemt ved passiv overvågning udført af digitale enheder i den fysiske verden er alle blevet anvendt til samfundsvidenskabelig forskning [@salganik17]. Adgang til disse data kræver partnerskaber med deres ejere -- telefonfirmaer, regeringer, teknologiselskaber osv. Dette kan betyde, at man skriver software til at få adgang til websteder eller eksterne databaser eller kan involvere mere formaliserede partnerskaber for at dele information sikkert [@EL14]. I afsnittet om "Anskaffelse af data" nedenfor beskriver vi nærmere hvordan det kan finde sted.

The hurdle of accessing big data underscores a basic difference between it and traditional social science data: traditional social science data were collected for the purpose of doing social science. Social scientists must always consider the sources and the nature of our data, and big data has sometimes been referred to as "found data" or "digital exhaust" [@harford14]. What does this mean? Virtually all big data are purpose-built for goals *other than* social research. Metadata like timestamps, follower counts, or activity frequencies on social media web sites are not stored for science or, necessarily, according to scientific standards. Although they may be useful, their scientific value is an unintended byproduct (i.e. exhaust) of business or government activity. As such, when applying big data to social science research we must always probe the implications of the data's purpose for our scientific applications.^[As @salganik17 puts it, the challenges and opportunities created by big data follow from asking why the data were collected.]


- How/why big data became what it is in the zeitgeist
  - Classic advantages: Big / always on
  - Classic disadvantages: metered/restricted access + expertise barrier

- Definition of machine learning: "y-hat vs. beta-hat"

# Big data og forskningsdesign

Systems that collect big data are purpose-built, and the purpose is never political science research. This holds true even for the most research-friendly data sources.

<!-- Include example about retsinformation.dk?? Ministry titles in official metadata reflect "current" institutional structure and throws out information contemporary to older data. This creates a massive headache for researchers, but it makes perfect sense for running an efficient bookkeeping operation for the central bureaucracy. Furthermore, there are not metadata linking laws to the decrees, regulations, etc. that they enable. This system would be superfluous and redundant since retsinformation is a broad-based clearing house and wouldn't necessarily be the tool of choice for legal advisors drafing secondary legislation within the line ministries. The data in the official gazette are complete, but they come with major biases caused directly by the fact that--even this public, non-partisan resource--is built with a purpose that is different from (not necessarily opposed to) political science research.

To cap it off, retsinformation.dk isn't finished evolving. It will continue to develop in ways that may or may not benefit political science research as its maintainers' and users' needs and preferences change.-->

- Big data typically *not designed for research*, i.e.
  - it's dirty (re: Salganik) -- human behavior is mixed together with actions taken by bots/automated systems
  - drifting -- Needs of *actual* system maintainers / users may be completely orthogonal to needs of political science research (or even opposed, consider FB)
  - algorithmically confounded -- large-scale systems have robot nannies. These include everything from spell checkers to YouTube's recommendation algorithm. The observed behavior we find in big data is a consequence of the (generally) unobservable interaction between humans and these algorithms.

- Standard sampling issues (nonrepresentative, systematic sampling bias)




# Behandling af big data

## Anskaffelse af data

- Getting data: scraping, APIs, text databases

## Usuperviserede tilgange


## Superviserede tilgange


## Tekst som data



- Pattern discovery (dimensionality reduction -- a la argument in Lowe 2013WP)
  - Generic data: Clustering, IRT, etc.
  - Fundamental unity of goals and approach
  - Variety in methods results from variation in:
    - Assumptions re: underlying model/geometry of latent space
    - Related to above: something like, "format" of output
    - Structure/nature of input data
    - Amount of domain expertise applied to structure results
    - Assumptions about what is correlated with what
    - Level of computational intensity

- Text: Topic modeling, text scaling, dictionaries

- Classification / prediction

- Explanatory modeling


# Etiske problemer ved big data

emotional contagion example: @kramer2014experimental

problem: lack of informed consent

complication: under surveillance capitalism, all citizens are subject to constant experimentation w/o consent



<!-- ## Skills -->

<!-- - Data collection / management -->
<!-- -  -->
