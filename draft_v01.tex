\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[12pt,]{article}
\usepackage[]{cochineal}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={`Big data' og politologisk datavidenskab},
            pdfauthor={Frederik Hjorth; Matt W. Loftis},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1in]{geometry}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\usepackage[]{natbib}
\bibliographystyle{apsr}

\title{`Big data' og politologisk datavidenskab}
\providecommand{\subtitle}[1]{}
\subtitle{Udkast, april 2020}
\author{Frederik Hjorth \and Matt W. Loftis}
\date{}

\begin{document}
\maketitle

`Big data' er overalt. Det gælder i dobbelt forstand: takket være
drastiske stigninger i computeres hukommelse og regnekraft indeholder
næsten alle computere i dag store, ustrukturerede datamængder. Mange af
disse data er biprodukter af menneskelig adfærd, som i dag registreres
og kvantificeres i historisk uset omfang. Men big data er også overalt i
den forstand at begrebet `big data' og beslægtede begreber er blevet
almindeligt kendte og bredt anvendte, og ikke mindst genstand for stor
kommerciel interesse. En hyppigt citeret artikel fra \emph{Harvard
Business Review} kaldte således ``data scientist'' for ``det 21.
århundredes mest sexede job'' \citep{davenport2012data}.

Alene den begrebslige udbredelse af big data gør det relevant at vide
hvad det nærmere dækker over. Men big data er også reelt et væsentligt
nybrud i forhold til de data og metoder, politologi og samfundsvidenskab
traditionelt har betjent sig af. Big data muliggør analyser af
politologiske emner som ville have været umulige med traditionelle
metoder, men kræver også nye teknikker og metodiske værktøjer.

Formålet med dette kapitel er at introducere til de datatyper og
metoder, begrebet big data dækker over. Først opridser vi begrebets
betydning og historie. Dernæst diskuterer vi hvordan en række
karakteristika ved big data skaber særlige udfordringer i forhold til at
udvikle stærke forskningsdesigns. Herefter præsenterer vi en række
specifikke tekniske værktøjer til behandling af big data. Afslutningsvis
opridser vi nogle væsentlige etiske problematikker i relation til brugen
af big data.

cites: \citet{mullainathan2017machine}, \citet{varian2014big}

\hypertarget{hvad-er-big-data}{%
\section{Hvad er big data?}\label{hvad-er-big-data}}

I en toneangivende artikel peger \citet{lazeretal} på big data som
kilden til en ny type samfundsvidenskab, ``computational social
science'', med ``kapacitet til at indsamle og analysere data med
historisk uset bredde, dybde og omfang''. Men begrebet big data lever to
liv. På den ene side er den populære definition af begrebet forbundet
med futuristiske løfter om ny, datadrevet videnskab og teknologi. På den
anden side står hvad man kunne kalde den operationelle definition af
hvordan store datamænger indsamles, lagres og analyseres af
samfundsvidenskabsfolk. For at belyse betydningen af big data for
politologi betragter vi først denne anden, operationelle betydning af
begrebet inden vi vender tilbage til den første, populære betydning.

En bredt anvendt operationel definition identificerer big data med de
såkaldte `tre V'er': \emph{Volume}, \emph{Variety} og \emph{Velocity},
dvs. omfang, variation og hastighed \citep{laney01}. Big data refererer
her til foranderlige og meget store datasæt -- inklusive data der er for
store til at gemme på en almindelig pc -- der indeholder masser af
variation. Datakilder af denne art er ofte interessante for
samfundsvidenskab: søgemaskinelogfiler, sociale medieaktiviteter,
offentlige registre, mobiltelefonregistre eller endda data gemt ved
passiv overvågning udført af digitale enheder i den fysiske verden er
alle blevet anvendt til samfundsvidenskabelig forskning
\citep{salganik17}. Adgang til disse data kræver partnerskaber med deres
ejere -- telefonfirmaer, regeringer, teknologiselskaber osv. Dette kan
indebære at man skriver software til at få adgang til websteder eller
eksterne databaser eller kan involvere mere formaliserede partnerskaber
for at dele information sikkert \citep{EL14}. I afsnittet om
``Anskaffelse af data'' nedenfor beskriver vi nærmere hvordan det kan
finde sted.

Dette peger også på en vigtig forskel mellem big data og traditionelle
samfundsvidenskabelige data: traditionelle samfundsvidenskabelige data
er typisk indsamlet med samfundsvidenskab som formål. I modsætning
hertil omtales big data til tider som ``fundne data'' eller ``digital
udstødning'' \citep{harford14}. Hvad betyder det? Næsten alle big data
er udviklet til \emph{andre formål} end samfundsforskning. Metadata
såsom tidsmarkører, antal følgere, eller aktivitetsmål på sociale medier
lagres ikke for videnskabens skyld - eller nødvendigvis i
overensstemmelse med videnskabelige standarder.

Selv offentlige datakilder kan udvise dette problem. Betragt for
eksempel et lille, men illustrativt eksempel: lov nr. 1049 af
11/12/1996. Loven er ganske kort, færre end 20 ord. Det eneste den gør
er at ophæve lov om skoleskibsafgift. Civilstyrelsens database med al
dansk lovgivning, Retsinformation, angiver adskillige stykker metadata
om lov nr. 1049 (jf.
\texttt{https://www.retsinformation.dk/Forms/R0710.aspx?id=83509}).
Metadata angiver f.eks. den lov der ophæves, adskillige relaterede
dokumenter, lovens offentliggørelsesdato, og dens ministerområde. Men
dette sidste datapunkt er lidt forvirrende. Ministerområdet for lov nr.
1049 er angivet som ``Uddannelses- og Forskningsministeriet''. Men loven
er underskrevet af Mimi Jakobsen, som var erhvervsminister i regeringen
Poul Nyrup Rasmussen II. Så hvorfor er loven ikke tilknyttet
Erhvervsministeriet? Fejlen opstår fordi Civilstyrelsen opdaterer
lovgivning løbende så den afspejler lovgivningens ressortområde \emph{i
dag}. Koblingen af lov nr. 1049 til Uddannelses- og
Forskningsministeriet er indlysende forkert hvis du skal bruge
historiske data om dansk lovgivning. Uheldigvis for politologer er det
korrekt hvis du - som Civilstyrelsen - ikke har til formål at bedrive
historisk forskning, men i stedet vil organisere gældende dansk
lovgivning efter ministerområder. For at gøre ondt værre kan
Retsinformation ændre sig yderligere i fremtiden på måder der ikke
gavner politologien, alt efter hvad der tjener Civilstyrelsens behov.

Når man analyserer big data der er produceret til et eksisterende privat
eller offentligt formål lurer problemer af denne type konstant. Selvom
big data kan være enormt værdifulde for samfundsvidenskaben er deres
værdi en \emph{utilsigtet bivirkning} af kommerciel aktivitet eller
myndighedsudøvelse. Når vi anvender big data i forskningsøjemed er det
derfor altid vigtigt at forstå hvorfor og hvordan data er opstået til at
begynde med, og tænke igennem hvilke implikationer det har for vores
videnskabelige anvendelse. Som \citet{salganik17} formulerer det følger
både udfordringer og muligheder ved big data af at spørge sig selv
hvorfor data blev indsamlet i første omgang.

\hypertarget{kilder-til-big-data}{%
\section{Kilder til big data}\label{kilder-til-big-data}}

Det er ofte en møjsommelig proces at indsamle samfundsvidenskabelige
data. Derfor fremhæves det ofte som en fordel ved big data at
undersøgelsens subjekter selv genererer data: en forsker kan eksempelvis
indsamle millioner af tweets om et politisk emne uden skulle uddele et
eneste spørgeskema. Men selv om data er genereret på forhånd er det ikke
ligetil at \emph{anskaffe} sig data. Der er groft sagt tre måder man kan
gøre det på.

Den første og mest umiddelbare måde er at udtrække data direkte fra
websider, typisk kaldet \emph{scraping}. Scraping udnytter at indholdet
på de fleste større websider kommer fra databaser som fremstiller
indholdet i websider med en konsistent struktur. Ved at hente kildekoden
til disse websider, på samme måde som en webbrowser gør det, kan man
udtrække data på en konsistent måde. Hvis man f.eks. besøger websiden
for \emph{Lov om ophævelse af lov om skoleskibsafgift} hos
Retsinformation finder man i sidens kildekode bl.a. dette:

\begin{verbatim}
<div class="metadata-summary">
            <span class="kortNavn">LOV nr 1049 af 11/12/1996 Gældende</span><br>
      <div class="ressort">
                Offentliggørelsesdato: 12-12-1996<br>
        Uddannelses- og Forskningsministeriet
            </div>
        </div>
\end{verbatim}

Kodestumpen viser at Retsinformations database lagrer lovens navn i
feltet \texttt{kortNavn} og lovens offentliggørelsesdato og
ressortområde i feltet \texttt{ressort}. Takket være den stringente
kodestruktur er det nemt at gemme disse og andre metadata i et
analyserbart format. Og fordi kodestrukturen er ens på tværs af love hos
Retsinformation kan man scrape data om tusindvis af andre love med samme
lille stykke kode.

Når man indsamler data ved hjælp af scraping tilgår man i princippet
data på samme måde som en almindelig internetbruger der benytter sig af
en browser. Men fordi scraping gør det muligt at hente kolossale
datamængder er det også en kontroversiel praksis. Et illustrativt
eksempel på det kommer fra en meget omtalt juridisk strid mellem det
sociale netværk LinkedIn og analysefirmaet HiQ. En del af HiQ's
forretningsmodel er at analysere arbejdsmarkedet for it-specialister, og
HiQ har bl.a. høstet data ved at scrape data fra offentlige profiler på
LinkedIn. I 2017 sagsøgte LinkedIn HiQ med påstand om at HiQ's
scraping-praksis var et brud på amerikansk it-lovgivning. HiQ fik til
sidst medhold i at virksomheden kunne scrape data fra offentlige
LinkedIn-sider uden tilsagn fra LinkedIn, men sagen illustrerer at
scraping ofte finder sted i en juridisk gråzone.

Kodestumpen om \emph{Lov om ophævelse af lov om skoleskibsafgift} kommer
fra Retsinformation, og det er som hovedregel ikke forbudt at scrape
data fra offentlige hjemmesider, så længe man ikke urimeligt belaster
udbyderens servere. Man bør dog uanset kilden altid sikre sig tilsagn
fra dataudbyderen før man går i gang med at scrape data.

En anden måde at hente data på er gennem såkaldte API'er. API står for
\emph{Application Programming Interface} og er en slags kontrolleret
adgang til data hos en dataudbyder. API'er indebærer altså ikke samme
juridiske usikkerheder som scraping, da udbyderen selv stiller data til
rådighed og definerer rammerne herfor. Eksempelvis har mange API'er
\emph{rate limits} der sætter grænser for hvor meget data man kan hente
ad gangen.

Princippet om at big data ikke er lavet for samfundsforskningens skyld
gælder også for API'er. Det egentlige formål for de fleste API'er er at
dele data på tværs af kommercielle platforme. For eksempel er det API'er
der muliggør at et online-medie kan vise hvilke af ens egne
Facebook-venner der har `liket' en specifik artikel, fordi avisen kan
tilgå data om læserens Facebook-netværk gennem Facebooks API. Men mange
sociale netværk stiller meget righoldige data til rådighed for forskere
gennem API'er. For eksempel bruger \citet{hjorth2019}, som studerer
rækkevidden af online misinformation, Twitters API til at indsamle data
om ca. 13 millioner følgere af ca. 10.000 Twitter-konti. Offentlige
myndigheder stiller også i stigende grad data til rådighed gennem
API'er. Eksempelvis stiller Folketinget data om medlemmer, forhandlinger
og lovarbejde til rådighed gennem en API.

En tredje måde at få adgang til big data er gennem et egentligt
samarbejde med virksomheder der lagrer big data. For eksempel
rapporterer \citet{bond2012} om et eksperiment, hvor samfundsforskere i
samarbejde med Facebook randomiserede hvilken type information
Facebook-brugere fik om deres venners stemmeadfærd. I kraft af
samarbejdet kunne forskerne udføre eksperimentet i en uhørt stor skala:
eksperimentet involverede i alt 61 millioner Facebook-brugere.

Studiet af Bond m.fl. er exceptionelt fordi det kombinerer kvaliteterne
ved big data og eksperimentel metode. Mange forskere gør derfor også en
stor indsats for at etablere samarbejder med virksomheder og
organisationer der kan give dem adgang til data, der ellers ville være
utilgængelige. Men samarbejde med virksomheder om big data er ikke uden
faldgruber. For det første kræver det ofte et betydeligt bureaukratisk
benarbejde at etablere et samarbejde. For det andet, og mere principielt
problematisk, er virksomheder og organisationer sjældent interesserede i
forskning der stiller dem selv i et dårligt lys. Det kan betyde at nogle
typer undersøgelser prioriteres på bekostning af andre, alene fordi de
passer bedre til store teknologivirksomheders dagsordener. Eksempelvis
konkluderede \citet{bond2012} at Facebook-kampagnen havde en gunstig
effekt på valgdeltagelse. Det er i sagens natur en flatterende
konklusion for Facebook. Men det er uklart om forskerne havde haft samme
frihedsgrader til at studere de negative konsekvenser af at bruge
Facebook.

\hypertarget{big-data-og-forskningsdesign}{%
\section{Big data og
forskningsdesign}\label{big-data-og-forskningsdesign}}

Big data has applications in political science in empirical studies of
all types, from description to explanation, prediction, and causal
studies. Although these applications are only beginning across the
social sciences, the past 15 years have provided enough experience that
we can already point to one strong finding that can always guide us when
we apply big data in our work: research design still matters
\citetext{\citealp[see][p.~13]{toshkov16}; \citealp{CG15}}.

\emph{Familiar sampling bias}

Perhaps the most heady idea about big data was expressed best in the,
now infamous, article in \emph{Wired} magazine by Chris
\citet{anderson08} -- the idea that big data eliminates sampling
problems because \emph{n}=all. That is, one can analyze all of the data.
The article has met with a good deal of attention and pushback in the
years since it was published. In early 2020, it boasts more than 2.000
citations on Google Scholar. To put that in perspective, Maurice
Duverger's book \emph{Political Parties}, the origin of political
science's only finding that rises to the level of a law, was published
in 1959 and counts just over 7.000 citations.

The concept of ``\emph{n}-all'' implies that big data can be taken at
face value. Its patterns reveal a complete picture of human behavior.
Unfortunately, the selection problem is still with us. It arises
whenever observations enter your data for systematic reasons.
\citet{AP08} illustrate the problem with an example from the National
Health Interview Survey in the US, in which individuals are asked to
rate their health on a scale. Perhaps surprisingly, they find that
individuals in hospitals systematically rate their health as worse than
those out of hospital. Is the obvious conclusion that hospitals make
people sicker? Of course not, individuals in hospital \emph{selected}
into being in the hospital because they were sicker.

Similar situations often arise with big data. For example,
\citet{harford14} recounts the story of Boston's experiment with using
cell phone tracking to identify pot holes in the streets that need
repair. The result was that the city discovered every pothole in
neighborhoods frequented by young, affluent drivers--they type of person
who owned a smart phone and downloaded the city's app. Likewise,
\citet{TSSW10} confirm the finding in previous research that Twitter
mentions of German parties correlated strongly with their vote share in
the 2009 parliamentary elections, with one major exception. The
extremely online \emph{Pirate Party} garned a huge number of mentions on
Twitter, while receiving a tiny fraction of the actual vote. In both of
these cases, if \emph{n}=all then it equals ``all'' of a specific,
self-selected group of technology users.

Ignoring sampling bias has always meant that researchers risked finding
the wrong answer. Using big data with biased samples simply means now we
get extremely precise estimates of the wrong answer.

\emph{Special headaches for big data}

Big data also confronts us with new sources of bias and confounding.
Perhaps the most famous example for social scientists is that of Google
Flu Trends (GFT). GFT was a Google project launched in 2008 that
predicted regional flu epidemics from fine-grained data on users queries
to Google about their symptoms \citep{Getal2009}. After initially
receiving attention for its impressive accuracy, GFT's predictive
performance began to diminish systematically over time until--by the
time the project was shuttered in 2015--for years it had produced
inaccurately high estimates sometimes as great as double the data
reported by US Centers for Disease Control and Prevention
\citep{harford14}. The reasons for GFT's collapse are instructive for
understanding both why research design still matters and what new
headaches come with big data.

Several things contributed to GFT's problems, but the most noteworth
seems to have arises after Google adjusted its main search service
\citep[see][]{LKKV14}. Google, like many organizations that produce and
process big data, is constantly updating its service. In 2011 and 2012,
Google added functions that suggested additional search terms to users
(based on their initial search terms) and even suggested possible
diagnoses for search terms that involved symptoms. The upshot was a
feedback loop: users of Google search were nudged to refine their
searches for symptoms and to seek out information on the flu,
intensifying the signals that GFT relied on to predict flu outbreaks.
There is more to GFT's story, of course, but this highlights some
important principles for researchers to keep in mind.

Big data in political science research designs: - addressing confounding
- it's dirty (re: Salganik) -- human behavior is mixed together with
actions taken by bots/automated systems - drifting -- Needs of
\emph{actual} system maintainers / users may be completely orthogonal to
needs of political science research (or even opposed, consider FB) -
algorithmically confounded -- large-scale systems have robot nannies.
These include everything from spell checkers to YouTube's recommendation
algorithm. The observed behavior we find in big data is a consequence of
the (generally) unobservable interaction between humans and these
algorithms.

\hypertarget{measurement-stuff}{%
\subsection{measurement stuff}\label{measurement-stuff}}

\begin{itemize}
\tightlist
\item
  role of big data in the research design

  \begin{itemize}
  \tightlist
  \item
    uncommon to directly analyze
  \item
    more often: measurement
  \end{itemize}
\end{itemize}

\hypertarget{behandling-af-big-data}{%
\section{Behandling af big data}\label{behandling-af-big-data}}

Big data præsenterer både computationelle og analytiske udfordringer -
vi fokuserer på analytiske

Fællestræk: højdimensionalitet

Fælles for metoder: dimensionalitetsreduktion

Klassifikation ctr. skalering

usuperviserede tilgange

superviserede tilgange

\hypertarget{etiske-problemer-ved-big-data}{%
\section{Etiske problemer ved big
data}\label{etiske-problemer-ved-big-data}}

emotional contagion example: \citet{kramer2014experimental}

problem: lack of informed consent

complication: under surveillance capitalism, all citizens are subject to
constant experimentation w/o consent

\bibliography{references.bib}

\end{document}
