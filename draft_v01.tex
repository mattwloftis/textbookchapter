\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[12pt,]{article}
\usepackage[]{cochineal}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={`Big data' og politologisk datavidenskab},
            pdfauthor={Frederik Hjorth; Matt W. Loftis},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1in]{geometry}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\usepackage[]{natbib}
\bibliographystyle{apsr}

\title{`Big data' og politologisk datavidenskab}
\providecommand{\subtitle}[1]{}
\subtitle{Udkast, april 2020}
\author{Frederik Hjorth \and Matt W. Loftis}
\date{}

\begin{document}
\maketitle

`Big data' er overalt. Det gælder i dobbelt forstand: takket være
drastiske stigninger i computeres hukommelse og regnekraft indeholder
næsten alle computere i dag store, ustrukturerede datamængder. Mange af
disse data er biprodukter af menneskelig adfærd, som i dag registreres
og kvantificeres i historisk uset omfang. Men big data er også overalt i
den forstand at begrebet `big data' og beslægtede begreber er blevet
almindeligt kendte og bredt anvendte, og ikke mindst genstand for stor
kommerciel interesse. En hyppigt citeret artikel fra \emph{Harvard
Business Review} kaldte således ``data scientist'' for ``det 21.
århundredes mest sexede job'' \citep{davenport2012data}.

Alene den begrebslige udbredelse af big data gør det relevant at vide
hvad det nærmere dækker over. Men big data er også reelt et væsentligt
nybrud i forhold til de data og metoder, politologi og samfundsvidenskab
traditionelt har betjent sig af. Big data muliggør analyser af
politologiske emner som ville have været umulige med traditionelle
metoder, men kræver også nye teknikker og metodiske værktøjer.

Formålet med dette kapitel er at introducere til de datatyper og
metoder, begrebet big data dækker over. Først opridser vi begrebets
betydning og historie. Dernæst diskuterer vi hvordan en række
karakteristika ved big data skaber særlige udfordringer i forhold til at
udvikle stærke forskningsdesigns. Herefter præsenterer vi en række
specifikke tekniske værktøjer til behandling af big data. Afslutningsvis
opridser vi nogle væsentlige etiske problematikker i relation til brugen
af big data.

cites: \citet{mullainathan2017machine}, \citet{varian2014big}

\hypertarget{hvad-er-big-data}{%
\section{Hvad er big data?}\label{hvad-er-big-data}}

I en toneangivende artikel peger \citet{lazeretal} på big data som
kilden til en ny type samfundsvidenskab, ``computational social
science'', med ``kapacitet til at indsamle og analysere data med
historisk uset bredde, dybde og omfang''. Men begrebet big data lever to
liv. På den ene side er den populære definition af begrebet forbundet
med futuristiske løfter om ny, datadrevet videnskab og teknologi. På den
anden side står hvad man kunne kalde den operationelle definition af
hvordan store datamænger indsamles, lagres og analyseres af
samfundsvidenskabsfolk. For at belyse betydningen af big data for
politologi betragter vi først denne anden, operationelle betydning af
begrebet inden vi vender tilbage til den første, populære betydning.

En bredt anvendt operationel definition identificerer big data med de
såkaldte `tre V'er': \emph{Volume}, \emph{Variety} og \emph{Velocity},
dvs. omfang, variation og hastighed \citep{laney01}. Big data refererer
her til foranderlige og meget store datasæt -- inklusive data der er for
store til at gemme på en almindelig pc -- der indeholder masser af
variation. Datakilder af denne art er ofte interessante for
samfundsvidenskab: søgemaskinelogfiler, sociale medieaktiviteter,
offentlige registre, mobiltelefonregistre eller endda data gemt ved
passiv overvågning udført af digitale enheder i den fysiske verden er
alle blevet anvendt til samfundsvidenskabelig forskning
\citep{salganik17}. Adgang til disse data kræver partnerskaber med deres
ejere -- telefonfirmaer, regeringer, teknologiselskaber osv. Dette kan
indebære at man skriver software til at få adgang til websteder eller
eksterne databaser eller kan involvere mere formaliserede partnerskaber
for at dele information sikkert \citep{EL14}. I afsnittet om
``Anskaffelse af data'' nedenfor beskriver vi nærmere hvordan det kan
finde sted.

Dette peger også på en vigtig forskel mellem big data og traditionelle
samfundsvidenskabelige data: traditionelle samfundsvidenskabelige data
er typisk indsamlet med samfundsvidenskab som formål. I modsætning
hertil omtales big data til tider som ``fundne data'' eller ``digital
udstødning'' \citep{harford14}. Hvad betyder det? Næsten alle big data
er udviklet til \emph{andre formål} end samfundsforskning. Metadata
såsom tidsmarkører, antal følgere, eller aktivitetsmål på sociale medier
lagres ikke for videnskabens skyld - eller nødvendigvis i
overensstemmelse med videnskabelige standarder.

Even government data sources present this problem, sometimes in
confusing ways. Consider a minor example: lov nr 1049 af 11/12/1996. The
law is short, fewer than 20 words. The only thing it does is ophæve lov
om skoleskibsafgift. Civilstyrelsens database of all Danish law,
\emph{retsinformation.dk}, lists several pieces of metadata about lov nr
1049.\footnote{See:
  \url{https://www.retsinformation.dk/Forms/R0710.aspx?id=83509}} For
example, the metadata capture the law it repeals, several related
documents, its publication date, and ministerområdet. This last one is
confusing, however. Ministerområdet for lov nr 1049 is currently listed
as Uddannelses- og Forskningsministeriet. However, the law was signed by
Mimi Jakobsen. If you do some further research, you will find that Mimi
Jakobsen var Erhvervsminister i Regeringen Poul Nyrup Rasmussen
II.\footnote{\url{https://www.regeringen.dk/regeringer-siden-1848/regeringen-poul-nyrup-rasmussen-ii/}}
Why, then, is this law not connected to Erhvervsministeriet? This
confusion is caused because Civilstyrelsen opdaterer ministerområder
løbende based on \emph{today's} legal framework and ministries.
Connecting lov nr 1049 to Uddannelses- og Forskningsministeriet is
obviously wrong if you want to build a historical data set of Danish
law. Unfortunately for political scientists, it is correct if---like
Civilstyrelsen---your goal is not historical research, but instead to
organize the legislation currently in force in Denmark. To make matters
worse for researchers, retsinformation.dk will continue to evolve in
ways that may or may not benefit political science research, depending
on Civilstyrelsens future needs and goals.

When using big data built for some official or private purpose, problems
of this nature are always lurking. Although big data can be extremely
useful for social science, their scientific value is an \emph{unintended
byproduct} (i.e.~exhaust) of business or government activity. When
applying big data to social science research we must always understand
why and how the data were assembled and probe the implications of the
data's purpose for our scientific applications.\footnote{As
  \citet{salganik17} puts it, the challenges and opportunities created
  by big data follow from asking why the data were collected.}

\hypertarget{kilder-til-big-data}{%
\section{Kilder til big data}\label{kilder-til-big-data}}

Det er ofte en møjsommelig proces at indsamle samfundsvidenskabelige
data. Derfor fremhæves det ofte som en fordel ved big data at
undersøgelsens subjekter selv genererer data: en forsker kan eksempelvis
indsamle millioner af tweets om et politisk emne uden skulle uddele et
eneste spørgeskema. Men selv om data er genereret på forhånd er det ikke
ligetil at \emph{anskaffe} sig data. Der er groft sagt tre måder man kan
gøre det på.

Den første og mest umiddelbare måde er at udtrække data direkte fra
websider, typisk kaldet \emph{scraping}. Scraping udnytter at indholdet
på de fleste større websider kommer fra databaser som fremstiller
indholdet i websider med en konsistent struktur. Ved at hente kildekoden
til disse websider, på samme måde som en webbrowser gør det, kan man
udtrække data på en konsistent måde. Hvis man f.eks. besøger websiden
for \emph{Lov om ophævelse af lov om skoleskibsafgift} hos
Retsinformation finder man i sidens kildekode bl.a. dette:

\begin{verbatim}
<div class="metadata-summary">
            <span class="kortNavn">LOV nr 1049 af 11/12/1996 Gældende</span><br>
      <div class="ressort">
                Offentliggørelsesdato: 12-12-1996<br>
        Uddannelses- og Forskningsministeriet
            </div>
        </div>
\end{verbatim}

Kodestumpen viser at Retsinformations database lagrer lovens navn i
feltet \texttt{kortNavn} og lovens offentliggørelsesdato og
ressortområde i feltet \texttt{ressort}. Takket være den stringente
kodestruktur er det nemt at gemme disse og andre metadata i et
analyserbart format. Og fordi kodestrukturen er ens på tværs af love hos
Retsinformation kan man scrape data om tusindvis af andre love efter
samme princip.

\hypertarget{big-data-og-forskningsdesign}{%
\section{Big data og
forskningsdesign}\label{big-data-og-forskningsdesign}}

Big data in political science research designs: - addressing confounding
- it's dirty (re: Salganik) -- human behavior is mixed together with
actions taken by bots/automated systems - drifting -- Needs of
\emph{actual} system maintainers / users may be completely orthogonal to
needs of political science research (or even opposed, consider FB) -
algorithmically confounded -- large-scale systems have robot nannies.
These include everything from spell checkers to YouTube's recommendation
algorithm. The observed behavior we find in big data is a consequence of
the (generally) unobservable interaction between humans and these
algorithms. - Standard sampling issues (nonrepresentative, systematic
sampling bias) - its role - uncommon to directly analyze - more often:
measurement

\hypertarget{behandling-af-big-data}{%
\section{Behandling af big data}\label{behandling-af-big-data}}

\hypertarget{anskaffelse-af-data}{%
\subsection{Anskaffelse af data}\label{anskaffelse-af-data}}

\begin{itemize}
\tightlist
\item
  Getting data: scraping, APIs, text databases
\end{itemize}

\hypertarget{usuperviserede-tilgange}{%
\subsection{Usuperviserede tilgange}\label{usuperviserede-tilgange}}

\hypertarget{superviserede-tilgange}{%
\subsection{Superviserede tilgange}\label{superviserede-tilgange}}

\hypertarget{tekst-som-data}{%
\subsection{Tekst som data}\label{tekst-som-data}}

\begin{itemize}
\item
  Pattern discovery (dimensionality reduction -- a la argument in Lowe
  2013WP)

  \begin{itemize}
  \tightlist
  \item
    Generic data: Clustering, IRT, etc.
  \item
    Fundamental unity of goals and approach
  \item
    Variety in methods results from variation in:

    \begin{itemize}
    \tightlist
    \item
      Assumptions re: underlying model/geometry of latent space
    \item
      Related to above: something like, ``format'' of output
    \item
      Structure/nature of input data
    \item
      Amount of domain expertise applied to structure results
    \item
      Assumptions about what is correlated with what
    \item
      Level of computational intensity
    \end{itemize}
  \end{itemize}
\item
  Text: Topic modeling, text scaling, dictionaries
\item
  Classification / prediction
\item
  Explanatory modeling
\end{itemize}

\hypertarget{etiske-problemer-ved-big-data}{%
\section{Etiske problemer ved big
data}\label{etiske-problemer-ved-big-data}}

emotional contagion example: \citet{kramer2014experimental}

problem: lack of informed consent

complication: under surveillance capitalism, all citizens are subject to
constant experimentation w/o consent

\bibliography{references.bib}

\end{document}
